Imprint logo
Journal logo
Conceptual modeling of natural language functional requirementsVidhu Bhala R. Vidya Sagara,., S. AbiramibaMindtree Limited, IndiabDepartment of Information Science and Technology, College of Engineering, Anna University, Guindy, Chennai 600025, Indiaa r t i c l e i n f oArticle history:Received 10 March 2012Received in revised form 27 July 2013Accepted 11 August 2013Available online xxxKeywords:Automated requirements analysisConceptual modelingNatural language processingSyntactic analysisa b s t r a c tRequirements analysts consider a conceptual model to be an important artifact created during therequirements analysis phase of a software development life cycle (SDLC). A conceptual, or domain modelis a visual model of the requirements domain in focus. Owing to its visual nature, the model servesas a platform for the deliberation of requirements by stakeholders and enables requirements analyststo further reﬁne the functional requirements. Conceptual models may evolve into class diagrams dur-ing the design and execution phases of the software project. Even a partially automated conceptualmodel can save signiﬁcant time during the requirements phase, by quickening the process of graphicalcommunication and visualization.This paper presents a system to create a conceptual model from functional speciﬁcations, written innatural language in an automated manner. Classes and relationships are automatically identiﬁed fromthe functional speciﬁcations. This identiﬁcation is based on the analysis of the grammatical constructsof sentences, and on Object Oriented principles of design. Extended entity-relationship (EER) notationsare incorporated into the class relationships. Optimizations are applied to the identiﬁed entities duringa post-processing stage, and the ﬁnal conceptual model is rendered.The use of typed dependencies, combined with rules to derive class relationships offers a granularapproach to the extraction of the design elements in the model. The paper illustrates the model creationprocess using a standard case study, and concludes with an evaluation of the usefulness of this approachfor the requirements analysis. The analysis is conducted against both standard published models andconceptual models created by humans, for various evaluation parameters.© 2013 Elsevier Inc. All rights reserved.
1. Introduction
The requirements gathering and analysis phase, or the require-ments phase, in short, is the most critical phase in the softwaredevelopment life cycle (SDLC). During this phase, analysts collab-orate with project stakeholders to gather the requirements for aproject.The requirements serve as inputs to further phases of theSDLC, in terms of work content, and for the planning of sched-ule and effort. They need to be as complete as possible. Changesto requirements during subsequent phases of the project can bemore expensive than during the requirements phase. A major prob-lem with functional requirements is that of unstated or implicitAbbreviations: NLP, natural language processing; UML, uniﬁed modeling lan-guage; ER, entity relationship; EER, extended entity relationship; OOAD, objectoriented analysis and design; SDLC, software development life cycle; OO, objectoriented; NLTK, natural language tool kit; POS, part of speech..Corresponding author. Tel.: +91 442 266 3229.E-mail addresses: vidhubhala.r.vidyasagar@gmail.com (V.B.R. Vidya Sagar),abirami mr@yahoo.com (S. Abirami).
requirements, which stakeholders assume the analyst knows. Suchissues in the requirements phase can cause disagreements amongdevelopment teams and business teams much later, for instance,during acceptance testing, or after project launch, and can consumea lot of effort and time to correct.To safeguard against changes made later by the requirementsproviders, most projects require a signoff of the requirements by allstakeholders, including customers, developers, business analystsand testers. Although this could be part of the process or a con-tractual requirement in the project, various issues exist that canreduce the signoff process to an ‘in letter’, rather than ‘in spirit’activity.The requirements analysis phase is highly dependent on per-sonal opinions and is subjective in nature. Some stakeholders havetrouble understanding the requirements presented in the form oftext without the assistance of an analyst. It is important that thestakeholders are able to understand the requirements presentedby the requirements analyst and comprehend the impact of therequirements in a uniform and efﬁcient manner.While many tools exist to render and visualize requirementsmodels, not many tools exist to assist the requirements analyst dur-ing the requirements analysis phase. For the purpose of visualizing
the functional requirements, the conceptual or domain model isa valuable intermediate artifact. A conceptual model “represents‘concepts’ (entities) and relationships between ideas in a problemdomain” (CORDIS, 2013). The conceptual model, as deﬁned byLarman (2002) contains only domain entities and attributes, andrepresents the static model of a system. On the other hand, theUML based OOAD model resembles a UML class diagram (Boochet al., 2010) through the inclusion of class operations and inter-class relationships, which also represent the dynamic nature ofthe system in study. A conceptual model is considered to be efﬁ-cient in visual communication because it uses less space and fewersymbols to convey maximal information, as compared to naturallanguage requirements. The use of conceptual models is widelyrecommended in newer software development models like AgileModeling (Lefﬁngwell, 2011), and has been adopted by objected-oriented development models using UML (Ambler, 2005).A quality framework for conceptual model validation was ﬁrstproposed by LindLand et al. (1994), who presented a framework fora conceptual model covering the syntactic, semantic and pragmaticqualities of the model. Syntactic quality addresses the correctnessof the model through the use of a formal syntax. Semantic qualityaddresses the validity and the completeness of the conceptualmodel against the target domain, i.e., the domain from which thefunctional requirements are created. Pragmatic quality addressesthe efﬁciency of the conceptual model in ensuring that the audi-ence comprehends the information the model tries to convey. Eachquality is elaborated with goals, and the recommended means toachieve the goals. The availability of a quality framework and theparameters to measure the quality of the conceptual model, makeit a suitable choice for systematic requirements analysis.This article focuses on the automated extraction of concepts andtheir relations to create a conceptual model. The constructed con-ceptual model is based only on stated, i.e., explicit requirements. Implicit requirements do not appear in the model, and must beprovided in an explicit manner by the stakeholders during therequirements phase itself. The goal is to create a useful conceptualmodel that the analyst can use, to help the stakeholders understandthe requirements before they sign off and conclude the require-ments phase of the project.By automating the creation of the conceptual model, the ana-lyst can focus the attention of the stakeholders and herself/himselfon the analysis and reﬁnement of the models, rather than on thecreation of the same. This allows the requirements to go throughmultiple iterations within the same timeframe, resulting in require-ments that analysts and stakeholders are comfortable with.The basis of this work lies in the linguistic aspects of the Englishlanguage. Natural language sentences that constitute the func-tional speciﬁcations are parsed to understand their grammaticalstructures. Various design components such as classes, attributes,entities and relationships are then extracted from these parsedsentences, based on textual analysis.Our work addresses the syntactic aspects of the conceptualmodel quality. As a logical extension, we discuss Pragmatic qual-ity in Vidhu Bhala et al. (2012), which deals with the uniformity ofaudience perception, and is achieved through visualization tech-niques.The structure of this paper is as follows. In Section 2, a survey ofthe related work in this ﬁeld is offered. In Section 3, the architectureof the system is presented in the form of a visual layout of the func-tional blocks. The algorithms and functionality of each functionalblock and modules are detailed. Section 4 gives details of the imple-mentation. A working example illustrates each of the functionalblocks. In Section 5, an evaluation of the automated conceptualmodel is presented, and Section 6, gives the conclusion, along withthe achievements of the current research work, the shortcomingsand possible future work.
2. A survey of existing work
The trend in research in the area of automation of requirementsanalysis indicates, that although the need for automation was real-ized in the early 1990s (Kurt, 1995), the concept of the automationof this area has started gaining interest only recently, as is evidentfrom the recent appearances of journal and conference articles inthis area of research. A couple of reasons can be inferred for thisrenewed interest in this ﬁeld. One is the recent surge in research andsubsequent development in automatic text analysis, like parsersfor natural language, tagged corpora for speciﬁc needs, anaphoraresolvers etc., which have reduced the complexities of dealing withnatural language. Another reason is the evolution of diagrammingmodels like UML, and the ongoing attempts at standardizing thecontent of models. With the software industry converging to a fewstandard and well-known formats of requirements documentation,more focused research with wider application is possible.Yue et al. (2011) refer to the conversion of requirements intomodels as a transformation process. They present an extensivesurvey of the transformation processes. They discovered that ﬁvetypes of pre-processing techniques, i.e., lexical, syntactic, seman-tic and pragmatic analyses, and categorization were found to beused in isolation or in combination. The resulting models from thetransformation processes of the papers that were surveyed, werefound to have low efﬁciency, and lacked evaluation mechanisms.Their survey included 20 works, categorized into 16 transforma-tion approaches. They found that only 7 of the approaches wereautomated. Further, only 4 of the automated works could generateclass diagrams, object diagrams or conceptual models, while therest generated other types of analysis models like sequence dia-grams or state charts. The survey also indicates underlying issuesrelated to the evaluation of the completeness of rules used for trans-formation, due to the ambiguity of the English language. The fourapproaches that generated models similar to conceptual modelswere based on sentence pattern matching or shallow parsing. Theyrequired stringent rules on the pattern of the input sentences inthe requirements text, for example, sentences of the form – sen-tence, verb, object, closely relating to the use case mode of writingrequirements. Sanjay et al. (2010) explored the automatic creationof domain models from inputs that users provide in a spread-sheet. These inputs are processed as rules that represent individualevents connecting entities in the requirements. A tool creates anintermediate representation of the requirements from the parsedrules, from which the domain model is then created. Ambriola andGervasi (2006) present an extensive requirements modeling andanalysis tool called CIRCE, that is based on fuzzy reasoning. A cus-tomized parser is used to parse sentences from the requirementstext. User glossaries are provided manually to the tool. An expertsystem adds semantic information to the parsed information to cre-ate a ﬁnal model. In both these approaches, the nature of the inputtext is constrained either through the use of templates, or throughthe use of a text that a parser can process.Mu et al. (2009) parsed natural language requirements usingtyped dependencies, and extracted requirements from the func-tional requirements speciﬁcations. Their objective is to assess thenon-functional requirements. While it might have been possible touse a free form input text, the authors require the input text to be ina standard format. They classify 10 types of semantic cases basedon the sentence structure. The output is not a conceptual model,but a customized format for their speciﬁc needs.Most of the publications discuss solutions that impose con-straints on the language used for the requirements, with very fewattempting to use natural language. Elbendak et al. (2011) representthe requirements model by semi-automatic processing of require-ments presented in use cases, that are written in natural language.Their work, which motivated our research, attempts to analyze
natural language requirements through shallow parsing. Manualintervention is required to aid the modeling process, with linguisticrules deﬁned to guide the user in creating the model. The outputis an extended entity relationship diagram. A limitation of theirmethod is that, it is restricted to simple sentence structures, andit requires human interaction. However, their research presents anevaluation mechanism that we have used in our research as well.As of writing this article, most research remains in the concep-tual stage, as is evident from the pattern of published research work.While many conference papers have appeared in the past couple ofyears, only a handful of journal papers are seen. The trend clearlyindicates that this is a very nascent research area that is yet to beestablished, and very few results are available.The main contribution of this article is that, the methodologythat we propose does not constrain the sentences in the inputtext, i.e., the requirements, to a strict pattern on structure. Anothercontribution in comparison with the surveyed work is that, theuser interaction for the creation of the model is almost eliminated.Further, the automated conceptual model is evaluated using per-formance parameters, both against standard models and againstmodels that humans are likely to create.In line with the conceptual model quality framework, wepresent in this paper, a mechanism to generate a conceptual modelautomatically. We propose the usage of the Stanford Parser (2013)to parse the sentences from the requirements speciﬁcations text.The advantage of this Parser is that it can extract meaningful gram-matical sentence constructs in the form of typed dependencies,
on which we apply rules and generate appropriate constituentsof the conceptual model, i.e., classes, attributes, operations andrelations. Once the conceptual model is created to visualize thedomain of the requirements, a visual transformation of the result-ing model may be undertaken as described in Vidhu Bhala et al.(2012).While the resulting conceptual model may not be in a formatthat can be used in further design phases of the project, becauseit lacks semantic information, it can certainly be used to ﬁne-tunethe requirements.
3. Implementation
The functional blocks involved in the automatic creation of theconceptual model are shown in the high-level functional block dia-gram shown in Fig. 1. The boxes shaded in gray on the left showthe high level modules that represent the distinct and identiﬁablefunctional blocks that are executed in the sequence indicated bythe direction of the arrows. The white boxes represent the individ-ual modules within the functional blocks. The ﬁnal output, i.e., theconceptual model is marked with a star.The implementation was done in Python using NLTK (Bird et al.,2009). NLTK deﬁnes an infrastructure that can be used to buildnatural language programs in Python. It provides basic classesfor representing data relevant to natural language processing,and standard interfaces for performing tasks to solve complexproblems.
Image of Fig. 1
Fig. 1. High level system diagram.
The Stanford Parser is a natural language Parser that worksout the grammatical structure of sentences, i.e., which groups ofwords go together (as “phrases”) and which words are subjects orobjects of verbs. The Parser provides ‘Typed Dependencies’, other-wise known as grammatical relations. A typed dependency is of theform dep type (governor, dependent), where dep type is the relationbetween the governor and the dependent word in a sentence. Thisrepresentation provides a simple description of the grammaticalrelationships in a sentence. Along with the typed dependencies, theParser can also return the part of speech of each word in a sentence,in the form of part-of-speech or POS tags.
3.1. Conceptual modeling
The base conceptual model is created as a result of the ﬁrstfour functional modules, i.e., text pre-processing, syntactic featureextraction, design elements extraction and relation type classiﬁca-tion.Although the objective of our research is to create models fromnatural language requirements, we assume that the sentences inthe input text satisfy some basic requirements. Firstly, the sen-tences should be grammatically correct. Secondly, no negativestatements are to be used in the input text. For example a sentence,‘The administrator cannot grant privileges to blocked accounts’ shouldnot appear in the input text. Such statements do not contribute toconceptual models due to the nature of the model. Thirdly, eachsentence is assumed to contain its own reference to any subject orobject, i.e., no reference resolution is required on the input text.For example, a sentence, ‘An administrator can send him an email’should be written as ‘An administrator can send the customer anemail’. This constraint includes all types of reference expressions:deﬁnite noun phrases, pronouns, demonstratives, one-anaphora,etc. (Jurafsky and Martin, 2000). Of the input constraints stated,with the exception of incorrect statements, it is possible to includethe rest in future extensions without adding much complexity. Thismay be done by incorporating appropriate rules, reference resolu-tion algorithms, and a semantic analysis corresponding to each ofthe other three constraints. The input text is assumed to be freefrom non-functional requirements, because conceptual modelingis meant for functional and not non-functional requirements.3.1.1. Pre-processingIn typical natural language processing applications, functionslike word tokenization, stemming, etc. are performed during pre-processing. However, due to the usage of the Stanford Parser,most of the typical pre-processing activities are eliminated. Prepro-cessing is limited to performing sentence tokenization to identifysentence boundaries.3.1.2. Syntactic feature extractionIn syntactic feature extraction, the syntactic features of eachsentence and the overall text are extracted. For each sentence,grammatical dependencies for each word in the sentence areretained in the form of typed dependencies, and the POS i.e., part-of-speech tags. The nouns are stemmed, i.e., converted to their baseform. These results are combined to get a ﬁnal set of words classiﬁedinto their parts of speech. Each of these is examined further.1. Dependency Parsing and POS tagsThe Parser (2013) is run against each sentence to generatetyped dependencies. Typed dependencies give a simple repre-sentation of the grammatical relationships in a sentence thatcan be used effectively without too much linguistic experi-ence or knowledge. It is an effective way to extract relationsfrom sentences in natural language. For example, the sentence‘The employee’s name is saved to the database by the program’
yields the dependencies det(employee-2,The-1), poss(name-4,employee-2), nsubjpass(saved-6,name-4), auxpass(saved-6,is-5),det(database-9,the-8), prep to(saved-6,database-9), det(program-12,the-11), agent(saved-6,program-12), where each grammaticaldependency in the sentence is represented as a binary rela-tion with a dependency name (abbreviated), a governor anda dependent word. For instance, nsubjpass (saved-6, name-4)means that ‘name’ is the subject of a passive sentence for theverb ‘saved’. ‘name’ occurs at position 4, while ‘saved’ occurs atposition 6 in the sentence, where position refers to the positionof the word within the sentence. The Parser is capable of ﬁnd-ing 52 types of grammatical relations that can be representedas typed dependencies (Parser, 2013). The Parser also returnsthe part-of-speech (POS) tags. The POS tags and the grammaticaldependencies are retained for further processing.2. StemmingStemming is the process of reducing derived words to theirbase forms. For example, words like creating, and created arestemmed to create, and plural nouns are converted to singularforms. Stemming for words is done using the NLTK’s Word-Netlemmatizer module, which uses WordNet’s inbuilt morphyfunction to ﬁnd the inﬂected forms of the word (Morphy, 2013).WordNet is an online dictionary that includes many functionsthat semantically relate words, using functions. This is preferredover other morphological stemming algorithms like Porter orLancaster, because the output of the lemmatizer should be aword that may be used as a class, which is not guaranteed instandard morphological stemmers (Jurafsky and Martin, 2000).3. Extraction of grammatical occurrencesUsing POS tags, words are classiﬁed into nouns, verbs, adjec-tives or adverbs. Nouns are classiﬁed into proper and commonnouns. Each word in the text is categorized into a single part ofspeech. Table 1 shows the mappings used for categorization.The typed dependencies, stemmed words and the word cate-gories are then used to further extract design elements that willparticipate in the design of the conceptual model.3.1.3. Design elements extractionThe extraction of design elements that form the conceptualmodel is the core of the functional module. Here, we create the con-ceptual model from the building blocks of classes and relations. Thesyntactic information is used to determine the valid constituents ofthe conceptual model.At this stage, typed dependencies are available for each sen-tence. We examine the typed dependencies for each sentence
against a set of rules. In these rules, we explore the grammaticalrelationships among the constituents of the sentence, and decidewhether to create classes, attributes, objects or relationships.While some rules are from established linguistic patterns fromreference books, others are created afresh to take advantage of thedeep parsing method that is used to extract grammatical struc-tures. The rules are grouped into design rules. The identiﬁcation ofclasses, attributes, operations and relations is as a result of theserules. While design rules are generic statements about what con-stitutes design elements, implementation rules examine the typeddependencies to achieve the goals of the design rules. More thanone implementation rule could map to a design rule. The purposeof layering the rules as design and implementation rules in thismanner is to organize the rules better, with the design rules beingthe generic guidelines, and the implementation rules mapping intothe detailed implementation speciﬁcs. For example, while a designrule could state that the subject of a sentence could be a class name,the implementation rules explore various types of subjects, like thesubject of a passive sentence, active sentence, prepositional subject,etc.Design rules are categorized, based on their syntactic contri-bution to the model, into subject-object transformation rules, andrules for classes, relations, operations and attributes. Each of thedesign rule categories is examined further.3.1.3.1. Subject-object transformation rules. Some common rules,transformations and functions are applied along with other designrules. We call these subject-object transformation rules. There aretwo main categories of these rules, (1) change of subject and (2)creation of a compound subject using noun nominal or specialadjectives.Subject Object Transformation Rule 1: When a possession mod-iﬁer type of grammatical relation occurs in a sentence, the subject ischanged to refer to the owner of the possession.For example, “The employee’s name is saved to thedatabase by the program” yields the typed dependenciesdet(employee-2,The-1), poss(name-4,employee-2), nsubjpass(saved-6,name-4), auxpass(saved-6,is-5), det(database-9,the-8),prep to(saved-6,database-9), det(program-12,the-11), andagent(saved-6,program-12). The identiﬁed conceptual class inthis case becomes employee, and not name, although the subjectof the sentence is name due to the occurrence of the poss typeddependency that denotes a possession modiﬁer.Although this rule does not make much sense at the linguisticlevel, it is appropriate and speciﬁc for conceptual modeling. This isbecause the object is likely to be an attribute or a constituent partof the main subject.Subject Object Transformation Rule 2: Noun compound modi-ﬁers are combined with the noun to generate compound words.This rule creates a compound noun from a typed dependencyrelation. For example, the sentence, ‘An ATM accepts cash cards’results in the dependencies det(ATM-2,An-1), nsubj(accepts-3, ATM-2), nn(cards-5,cash-4), and dobj(accepts-3,cards-5). Although theobject is ‘cards’, as speciﬁed by the dobj relation, the presence ofnn, the noun compound modiﬁer relation indicates that cash cardis a compound noun, and must be the object in this relation.Subject Object Transformation Rule 3: An adjective that qualiﬁesa noun, where the adjective cannot be classiﬁed combines with thenoun subject to generate compound words.This rule decides whether a certain adjective qualiﬁes the under-lying noun as an attribute, in which case we call it classiﬁable, orwhether it adds a meaning or categorization of the noun in a man-ner that the domain model demands, in which case, we call thisan unclassiﬁable adjective. Depending on whether an adjective isclassiﬁable or not, it can be an attribute of a class or the name ofthe class. For example:
save button - Becomes a domain conceptual classred button - Button has an attribute red, which is categorized into coloras an attributeAn adjective is a word that describes, identiﬁes, modiﬁes orquantiﬁes something. In sentences, adjectives may be used in thepredicative form (The book was boring), attributive form (It was aboring book), or appositive form (The book, old and torn, was lying onthe ﬂoor) (Loberger and Shoup, 2009). Adjectives may be classiﬁedinto categories such as quantity, shape, size, color etc. based on var-ious criteria. In English, adjectives are examined for a category ﬁtin a certain order, through an ordering process (Col, 2013). The ﬁrstcategory of an adjective in an ordered list of categories determinesthe most likely category of that adjective.The order of adjective categories is implemented using a dic-tionary data structure that included a corpus of known classiﬁableadjectives. When queried with a candidate adjective, the dictionaryreturns a classiﬁcation type, in the order of the adjective categories,if it exists. If no classiﬁcation is returned, we conclude that theadjective is unclassiﬁed. For instance, in the previous example, redwould return a class ‘colour’, while save would not return a class.3.1.3.2. Identifying classes/entities. The identiﬁcation of relevantconceptual classes is important for the creation of the ConceptualModel. Because the inherent assumption that our research makesis that the requirements text is potentially incomplete, the moti-vation behind the construction of the ﬁnal conceptual model willbe to visualize which concepts are explained in detail in the text.Based on this objective, a key change is made to the fundamen-tal process of textual analysis to determine conceptual classes. Thebasic textual analysis (Elbendak et al., 2011) rules state thatAll nouns are candidate classesAll verbs are either candidate operations or candidate relationsIf all nouns get added to the list of classes, many unnecessaryclasses appear. These are usually irrelevant and may add to userconfusion and visual clutter in the conceptual model. So, we alteredthis basic rule to state that ‘A noun that appears as a subject is alwaysa class, but a noun that appears as an object may not be a class’. Thisrule is elaborated below.Class Rule 1: Any Noun that appears as a subject is always a classNouns that appear as subjects are found in several types of sen-tence constructs, as can be seen from the indicative list in Table 2.Each of the rules in the table is implemented as an implementationrule.Class Rule 2: Nouns occurring as objects participate in relations,but are not created as classes explicitlyThis rule ensures that if an entity is described at least oncedirectly, or indirectly, it will become a class. However, entitiesthat always occur only as objects of discussion, may not appear asclasses. In that situation, they will not participate in relations, butwill appear as class operations led by the governing verb (action)
under the subject ‘class’, performing the action. An exception tothis rule is when the object is an agent in a passive sentence,because the agent is responsible for performing the action.In the sentence ‘A bank owns an ATM’, class rule 1 ensures thatbank is created as a class, while class rule 2 creates ATM as a poten-tial class for the relation own. If ATM is described further in the text,then ATM will become a class using class rule 1; otherwise it willremain a candidate class, and will not occur as a separate class inthe conceptual model.Some standard class rules that have been in existence and havebeen well accepted in previous research works in this area are:Class Rule 3: Gerunds are created as classes (Elbendak et al.,2011; Burg, 1997)The Gerund forms of verbs are treated as class names.e.g., Borrowing is processed by the staff . Borrowing is a class.Class Rule 4: Nouns are always converted to their singular formElbendak et al. (2011)This is achieved by using the stemmed form of the word fromthe syntactic feature extraction phase. Because the word is a noun,stemming does not alter the basic morphology of the word.3.1.3.3. Identifying attributes of a class. Attributes of classes can bebroadly classiﬁed into two categories, i.e., nouns as attributes, andadjectives as attributes. When nouns are used as attributes of aclass (e.g., A book has an author), further information is required todecide whether it must really be an attribute or stand-alone, in thecontext of the domain. Adjectives, when used as attributes mustconvey a certain property like color, size, shape, etc.A key contribution of our work is the differentiation of adjectivesthat combine to form the class name, and adjectives that becomeattributes. We introduce a modiﬁed attribute rule for adjectives.Attribute Rule 1: A classiﬁable adjective, either in the predicateor attributive form signiﬁes an attributeThis rule uses the result of the adjective classiﬁer. If the adjectiveclassiﬁer returns a category for the adjective, the category is usedas the attribute of the subject that the adjective qualiﬁes.e.g., the red button glows when pressed. . Button has an attribute,colorOther rules that are used determine attributes of conceptualclasses adopted from previous research works are:Attribute Rule 2: A noun phrase which follows the phrase ‘iden-tiﬁed by’, ‘recognized by’ indicates the presence of an attribute(Elbendak et al., 2011)e.g., An employee is identiﬁed by the employee id. . Employee hasattribute employee idAttribute Rule 3: An intransitive verb with an adverb may sig-nify an attribute (Elbendak et al., 2011)e.g., The train arrives in the morning at 8 AM. . Train has anattribute, timeAttribute Rule 4: A possessive apostrophe signiﬁes an attribute(Elbendak et al., 2011)e.g., The employee’s name is saved . Name is an attribute of theemployeeAttribute Rule 5: The genitive case when referring to a rela-tionship of the possessor using the ‘of’ construction signiﬁesan attribute (Elbendak et al., 2011)e.g., The name of the employee is printed. . Name is an attributeof the employeeThese rules are suitable for conceptual modeling in mostcases. However, there are some situations in which these canbecome inappropriate (Larman, 2002); for example, in the sen-tence phrases employee’s name, and employee’s briefcase, bothname and briefcase will become attributes of the employee class.There are differing opinions by authors of object-oriented model-ing techniques, on how to treat such situations. However, because
our need is to model the underlying explicit information, it is notpossible to determine if a given word should appear as an attributeor as a general association without further semantic information.The approach adopted in our research is to model such attributesas relations, which are then converted to attributes during post-processing, if there are no further references, justifying that theownership is contained within the class. This defers the decisionas to whether a given word is an attribute until we are sure that itis not important enough to be modeled as a class. Further researchinto the semantics of the attribute can determine if the referredword will become an attribute or entity associated with the subject(Larman, 2002).3.1.3.4. Identifying relation types. Once the conceptual classes, can-didate conceptual classes (i.e., nouns as objects) and attributes havebeen identiﬁed, they are combined to form relations. A relationis represented as R = (class a, card (class a), class b, card (classb), relation name), where class a, and class b are the participat-ing classes in a binary relationship, and card (class #) denotes themultiplicity with which a class participates. By virtue of the earlierrules, class a is already denoted as a class, while class b may be acandidate class which does not exist as a class. The following rulesidentify the relations:Relation rule 1: A transitive verb is a candidate for a relationshiptype (Elbendak et al., 2011)A transitive verb links a subject and an object. If the object trans-lates to a class (as per Class Rule 3), the verb becomes a relation.e.g., The banker issues a cheque . Relation (banker, 1, cheque, 1,issues)Relation rule 2: A verb with a preposition is a candidate for arelationshipA verb that contains a prepositional object linked to a transitiveverb along with a preposition combines with the preposition toform a relationship.e.g., The cheque is sent to the bank. . Relation (cheque, 1, bank,1, sent to)Relation rule 3: A sentence of the form ‘the r of a is b’ (Elbendaket al., 2011)Relation rule 4: A sentence of the form ‘a is the r of b’e.g., The bank of the customer is SBI . Relation (bank, 1, customer,1, SBI)e.g., SBI is the bank of the customer . Relation (bank, 1, customer,1, SBI)In the above sentences, r is the relation that relates class a toclass b. The above two rules are examples of the relation being inthe form of a noun, rather than a verb.In the design elements extraction phase, associations, composi-tions, and inheritance are all extracted in a common format, andthe classiﬁcation is done at a later stage.3.1.3.5. Identifying operations. Operations or class behaviors areused as dynamic aspects of a model. Although this is not the mainfocus of our research, operations are picked up anyway as a resultof sentence structure processing.Operation rule 1: An intransitive verb is an operation (Elbendaket al., 2011)An intransitive verb is a verb that has no direct object.e.g., The laptop hibernates. . hibernate is an operation of the lap-top.Operation rule 2: A verb that relates an entity to a candidateclass that is not created as an entity (fails Class Rule 2 aftercompletion of class identiﬁcation) becomes an operationOperation rule 2, as above is implemented by creating all sub-ject, verb, object combinations as generic class relations during the
design elements identiﬁcation stage. When the objects becometrivial, i.e., are not referenced as a subject elsewhere, the classbecomes a trivial class and the relation decomposes to a trivialrelationship, which is modeled as a class operation. For instance,in the sentence, an ATM accepts cash cards, according to classrules 1 and 2, ATM and cash card become classes and candidateclasses respectively. If the entity cash card were to be furtherdescribed, e.g., A cash card is made of plastic, then the cash cardbecomes a class; otherwise, the ATM class will contain the opera-tion accepts cashcard().3.1.3.6. Sample implementation rule and results. Design rules arecategorized as classes, attributes, operations, relations and subject-object transformation rules. Table 3 shows the design rulecategories and rule statements. Each design rule may be imple-mented through one or more implementation rules; i.e., speciﬁcimplementations of a generic class of design rules.The application of the implementation rule for a given designrule is illustrated in Fig. 2.The design rule ‘The r of a is b’ is a relation rule, expressed as animplementation rule
The sentence ‘The father of Tom is Jerry’, yields the dependenciesdet(father-2,The-1), nsubj(Tom-6,father-2), prep of(father-2,Jerry-4), cop(Tom-6,is-5). The results of this are Class(Tom), Class(Jerry),relation(Tom, Jerry, father).Similarly, Class Rule 1, states ‘Any Noun that appears as a subjectis always a class’ and is expressed as an implementation rule:
The sentence ‘The evaluation is conducted by a tech-nician’, yields the dependencies det(evaluation-2,The-1),nsubjpass(conducted-4,evaluation-2), auxpass(conducted-4,is-3), det(technician-7,a-6), agent(conducted-4,technician-7).
The results are Class(evaluation), Class(technician), Relation(evaluation, conducted by, technician).3.1.4. Relation types classiﬁcationThe relationships that have been created after, the extraction ofdesign features, are further classiﬁed as Associations, Aggregation,Composition and Inheritance or Generalization.3.1.4.1. Aggregation classiﬁcation. Aggregation can be found byconsidering clause patterns like ‘is made up of’, ‘is part of’, ‘contains’,‘consists’, ‘comprises’, etc.3.1.4.2. Composition classiﬁcation. Composition is a special typeof aggregation where there is a strong relationship between thewhole and the part. Due to lack of sufﬁcient information in thespeciﬁcation text, it may not always be possible to differentiatebetween composition and aggregation. Larman recommends thatwhen deciding, if you need to use composition over aggregation, ‘ifin doubt, leave it out’ (Larman, 2002). The implementation correctlyidentiﬁes one unambiguous type of sentence construct for compo-sition, where a mass noun is used, for example, a consortium ofbanks, or a ﬂeet of ships.3.1.4.3. Generalization classiﬁcation. Identiﬁcation of generaliza-tion relations is based on the presence of a copula verb, whichrelates two nouns, (proper or common nouns) in a sentence. Gener-alization is also based on the detection of preposition types, whichcontain words like type of, categories of, kinds of, etc.3.1.4.4. Post processing relations. After identifying aggregation,composition and generalization, the remaining relations can becategorized as associations. However, we recommend a post-processing phase to eliminate a few more relations, by creatingattributes and operations before the ﬁnal categorization.Post processing of relations refers to actions that are only pos-sible after all the relations and classes have been ﬁrmed up. Themain intention of this phase is to remove and compress unneces-sary detail; i.e., to coarse-grain the information that is extracted.This coarse-graining is based only on the implicit information in
Image of Fig. 2
Fig. 2. Illustration of an implementation rule under a design rule.
the text of the requirements, and not on human intelligence. Wepropose three types of Post Processing actions:3.1.4.4.1. Trivial relations to operations. Relationships that donot refer to an existing class are created as class operations of thegoverning class. Due to Class Rule 1, the governing class will alwaysexist.
(3)where R is the set of relations R ={class a, card(class a), class b, card(class b)re ln}.3.1.4.4.2. Trivial association to attributes. Relationships that arenamed ‘has’ or ‘have’ where there are no further references to thereferred entity are moved into the governing class as attributes.To enable this post-processing, during attribute identiﬁcation, allattributes found through the attribute rules are added to relationsusing the ‘has’/’have’ relation, rather than as direct attributes asillustrated in Table 4.3.1.4.4.3. Trivial class removal. In some cases functional spec-iﬁcations include non-functional speciﬁcations or actor actions.Human intelligence can easily remove such classes from con-sideration. However, the implementation does not consider thesemantics of each word. To deal with this problem, we deﬁne triv-ial classes, and remove all relations that contain this trivial class.
Trivial classes could include words like ‘system’, ‘software’, ‘inter-face’, etc. This list, however, cannot be considered as globallyapplicable, because the domain and scope of each requirementdeﬁnes what is trivial and what is not, and syntactic or semanticidentiﬁcation cannot replace human thinking.3.1.4.5. Association classiﬁcation. A relationship, that cannot becategorized into aggregation, composition or generalization, or pre-processed to trivial relations, is an association relation.
4. Case study
This section gives an implementation walkthrough of the con-ceptual model creation process with intermediate results. Theinput requirements speciﬁcation is taken from the ATM prob-lem statement (Rumbaugh et al., 1991). The passage is ﬁrstmanually modiﬁed to remove types of references, pronouns andwh-pronouns (who, whom, whose, whichever, whatever, etc.). Itis also modiﬁed to ensure consistent usage of a word for a statedsense, i.e., one sense per discourse.Modiﬁed ATM problem statement from Rumbaugh’s ATMmodel (Rumbaugh et al., 1991).
4.1. Conceptual modeling
In the preprocessing phase, the passage is broken down into sen-tences. The result of the syntactic feature extraction gives the listof adjectives, adverbs, verbs, proper and common nouns. The ﬁnallist that categorizes the words into parts of speech in the passageis:Adjectives ’computerized’, ‘appropriate’,‘individual’, ‘central’, ‘human’,‘concurrent’, ‘own’, ‘same’Adverbs ’directly’, ‘correctly’Nouns ’record-keeping’, ‘receipt’,‘cashier’, ‘consortium’, ‘computer’,‘user’, ‘data’, ‘card’, ‘account’,‘transaction’, ‘network’,‘provision’, ‘atm’, ‘system’,‘access’, ‘banking’, ‘station’,‘bank’, ‘cash’, ‘security’,‘software’Proper Nouns NoneCommon Nouns ’record-keeping’, ‘receipt’,‘cashier’, ‘consortium’, ‘computer’,‘user’, ‘data’, ‘card’, ‘account’,‘transaction’, ‘network’,‘provision’, ‘atm’, ‘system’,‘access’, ‘banking’, ‘station’,‘bank’, ‘cash’, ‘security’,‘software’In the ﬁnal list, ATM has assumed a common noun form. A nounthat occurs as a proper noun will assume a common noun form, ifused in that manner even once. In this case, the usage of ‘ATM’ inthe ﬁrst sentence ‘The system must support a computerized bankingnetwork that includes both human cashiers and ATMs’ – has causedATM to assume a common noun format.
Next, the design elements are extracted. The typed depend-encies of each sentence are passed through each implementationrule. The category of the resulting implementation rule determineswhat classes, attributes and relations are obtained for a phrase. Forinstance, for the sentence, An ATM communicates with a centralcomputer, the sequence used to check for rules for this statementis shown in Table 5.Each sentence is processed by different rules depending onthe sentence structure, presence of conjunctions, prepositionalsubjects, gerunds, etc. The ﬁnal results of the design elementsextraction for the given text, after all the rules have been executed,are:Classes:set([’atm’, ‘cashier’, ‘system’,‘consortium’,‘computerized banking network’,‘computer’, ‘central computer’,‘individual bank’, ‘bank’,‘cashier station’])Class relations:The list of relations and relation namesgenerated are shown in Table 6. Thespeciﬁc rule that was used to extractthe design elements is mentioned inthe last column. The advantage of theuse of dependency parsing is evidentfrom the fact, that the sentence isbroken down into fragments, and theimplementation rules are based onfragmented sentence structures, ratherthan on whole sentences.The generic relationships are then classiﬁed according totheir type, and trivial classes, and relationships are processedto eliminate them by moving them to attributes and operationsrespectively.
Aggregation classiﬁcation
Association classiﬁcationThe remaining relationships after going through all the abovesteps are retained as associations.
5. Performance evaluation
The Performance evaluation of this work was a challenge,because there is no deﬁnition of a ‘correct’ conceptual model. Theconceptual models that are traditionally created were found tocontain implicitly added knowledge by the analyst (which maybe incorrect, because of assumptions). Implicit information in theconceptual model could be related to classes or relations or both,that are not mentioned in the requirements text. For instance, inthe ATM example, Bank owns Bank Computer represents an implicitassumption on a relation, while the class Remote Transaction is animplicit assumption that a certain class exists, although it is notstated in the requirements explicitly.The evaluation is thus, biased against our implementation,because our implementation does not consider implicit infor-mation, but rather only models what is explicitly stated in therequirements. There are very few standard models which demon-strate conceptual models against given texts, with the model
aligning exactly with the text, rather than with an analyst’s opinionof the system.For the purpose of comparison, the standard models will consti-tute, where appropriate, concepts from standard books or authorresults, and implicit information, but will consciously, but subjec-tively, avoid any assumptions made on the end system that arenot stated in the requirements. A separate evaluation is done forimplicit information added to facilitate comparison.Because some conceptual classes are converted to attributes oroperations based on how much they have been elaborated on, the
Image of Fig. 3
Fig. 3. Sample implementation – conceptual model in UML format.
evaluation, where appropriate, also allows for such trivialized enti-ties to be counted as conceptual classes (making the assumption,that if the text is further elaborated, they will become classes). Twomodes of evaluation are considered:1. Evaluation against a sample from books or from experts2. Evaluation against human performance
5.1. Performance metrics used
We use performance metrics to compare our automatically gen-erated conceptual model against a standard published model or a
human model. The chosen metrics are precision, recall and over-speciﬁcation, as recommended by Elbendak et al. (2011). Precisionindicates the correctness or the relevance of the classes identiﬁed inthe conceptual model. The recall percentage indicates the ability ofthe automation to generate all classes. The over-speciﬁcation per-centage indicates the number of unnecessary, but correct classesthat the automation process includes in the generated conceptualmodel. The formulae for these measures are given below:
(7)
Image of Fig. 4
Fig. 4. Conceptual model with only classes, attributes and relations.
(8)
(9)Ncorrectis the number of correct classes identiﬁed; Nincorrectis thenumber of correct classes identiﬁed as wrong; Nmissingis the numberof classes extracted by the human expert and missed by the system;Nextra(valid)is the number of valid extra classes retrieved (differentfrom spurious).Although the model is not meant for understanding implicitknowledge, we evaluate it to compare it with human created mod-els. To calculate this, we introduce another variable, Nimplicit, whichdenotes the number of classes that are added that are correct andvalid, but not stated in the requirements.The formulae used to separate implicit knowledge are
(10)
(11)
(12)While some reference values are available for measures that donot include Nimplicit, published target values do not exist for anyof the measures. So, for the purpose of our evaluation, we deﬁnefavorable conditions to evaluate the performance. Recall and Preci-sion should be as high as possible, i.e., close to 100%, to accuratelyrepresent the target model. Over-speciﬁcation should be low, i.e.,close to 0%, to avoid adding too many additional details.
5.2. Results of conceptual class modeling against standard models
Table 8 shows the results of the performance evaluation againstsome case studies. The conceptual models that were generatedfor the EFP and the course registration case studies are shownin Figs. 6 and 7 respectively, while the ATM conceptual model isshown in Fig. 3. These case studies were used by various authorsto demonstrate the creation of class diagrams, and the corre-sponding results are found in the respective references, i.e., ATM(Rumbaugh et al., 1991), EFP (Kurt, 1995) and Course registration(IBM Corp, 2004). It must be noted, however, that these standard
Image of Fig. 5
Fig. 5. Manual results – statistical analysis.
models were neither built for the requirement analysis, nor cre-ated automatically, and thus incorporate an element of humanintelligence, which our implementation lacks.The application ofhuman judgment to add relevant classes is demonstrated by thedrop in precision. Our implementation added some classes thatwould be considered incorrect. The recall rate is very high becauseall classes are always considered candidate classes. However, theover-speciﬁcation measure, which should be low, shows high val-ues.Although high over-speciﬁcation values cause visual clutter inthe produced models, OO principles encourage over-speciﬁcationover under-speciﬁcation (Larman, 2002). Where there is no differ-ence between the results for the two columns, the reason lies inthe comparison model, rather than the proposed model’s ability tomodel implicit information.
5.3. Results against human subjects
Due to lack of a standard reference text and domain models,testing was conducted on human subjects. The subjects were 37ﬁnal year engineering students majoring in Computer Science andEngineering. They had undergone a course as part of their curricu-lum, which trained them theoretically and practically, in creatingclass diagrams from natural language speciﬁcations. The results oftheir ﬁnal CASE tools lab examination were taken for reference. Thestudents were given the requirements of the Course Registrationcase study, and they spent about 30–45 min creating the model.Fig. 5 shows the statistical results for the manual results, indicatingmedian values of approximately 40%, 70% and 10% for recall, pre-cision and over-speciﬁcation respectively. The results from Table 8are also shown on the graph.We see that our implementation is better than the overall stu-dents’ performance. It compares favorably against human workand against expert judgment for precision and recall. Two mainreasons for degraded over-speciﬁcation are lack of semantic infor-mation, and lack of judgment of words that cannot be classes. Forinstance, in EFP, a class name mean was created for a sentence, ‘atext document is created by author, word processor and some othermeans’.
5.4. Sample results of the evaluation of the performance ofrelations
The same metrics, i.e., recall, precision and over-speciﬁcation,are used to evaluate the performance of our implementation for therelationships among the classes. The results are shown in Table 9.The results against human subjects also show similar results forassociations, i.e., a very high over-speciﬁcation rate (95–140%) anda lower recall rate (50–70%) where implicit information is added.For the relations that are associations, the results indicate that the
over-speciﬁcation is very high when compared to manual results.This refers to valid relations that are not considered important orrelevant for inclusion in a conceptual model. Our implementationuses all forms of verbs to interconnect classes, because it is limitedto a textual analysis. Further coarse-graining may be required toretain only the most important relations among classes, therebyimitating the fuzzy nature of human thinking.When we consider cases where implicit information is used toapply assumptions on the relations based on human judgment,the recall rate also drops for associations. There are two reasonsfor this. Semantic relations are used to automatically link concep-tual classes, e.g., a bank – has – accounts, or cashier transaction –entered on – cashier station, even when not stated in the require-ments. Another reason is that, two or more ‘verb’ relations amongclasses are compressed into one single ‘verb’, e.g., bank owns com-puter, replaces other relationships like bank provides computer, orbank provides software for computer, etc.The results show a fairly good performance for relationships likegeneralizations, compositions and aggregations, in comparison tothe associations. These are special cases, and do not have muchambiguity or semantic compression.
6. Conclusion and future work
This paper has presented an approach to automate the genera-tion of a conceptual model from stated requirements. The resultsof the work so far indicate that a syntactic analysis on explicitlystated requirements is a primary step toward creating satisfactoryconceptual models, which may be used within the requirementsphase. The results compare favorably with human novice modeling.Our implementation has been able to successfully create con-ceptual models with reasonable precision and recall in a fullyautomated manner. We have been able to successfully applyvarious performance measures to evaluate the quality of the auto-matically generated models against human judgment, both expertand novice.The performance analysis shows that over-speciﬁcation of theconceptual classes and relations are a problem that might occludehuman comprehension for larger requirements models. Ratherthan attempting to coarse-grain, the concepts that translate to
classes in the model are assigned scores, and rendered as per theseto provide the context visually.During the course of our research, we realized that there cannotbe a comprehensive coverage of all kinds of natural language texts,for several reasons. Firstly, there exists no way to guarantee that agiven sentence is syntactically correct, and that the Parser chosen(Stanford) will yield the expected parse for it. Secondly, even if theresults are correct, the sentence structure may not have been codedin the rules, to extract the classes and relationships. Thirdly, thereexists no corpus of standard sentences that might be used in thelanguage of requirements. This is evident from the fact that start-ing from 12 rules in an established work, our implementation hasdevised a total of 38 rules that may still not be sufﬁcient to coverall kinds of sentence structures.A further constraint that was encountered was the inherentambiguity in the English language, especially in the area of deter-mining attributes (or aggregations) and in generalization. Forexample, whether book is an attribute of author, or author is anattribute of book depends on the availability of further information.Although our implementation overcomes such problems to someextent through deferring the decision of attribute vs. associationor relation vs. operation, problems inherent in English linguisticscannot be resolved.A few other limitations of the implementation are listed belowRelation attribute modeling – modeling relation attributes asseparate classes requires a deep NLP analysis of the prepositionalphrases related to adverbs. This slightly advanced feature of theconceptual model was not considered. Some researchers do advo-cate that relationship attributes should not be modeled.Implicit or non-stated modeling based on human intelligence– unstated or implicit information may be generated through asemantic analysis of the relationship between the classes. Becausethis information is not yet completely available, an implicit i.e.,Semantic processing of the conceptual model is not done.Sentence structure considerations – as in all NLP projects, theset of rules identiﬁed is intricately associated with the set ofsample case studies and examples from various sources. Thisdoes not indicate the completeness of the rule set, because theremay be peculiar sentence constructions for which rules may notbe framed, failing to identify appropriate subjects, objects and
relations. This can also happen when the construction of thesentence is ‘considered’ to be inappropriate in the context of theParser. Sentences without subjects like predicative sentences orpassive sentences with no agent are considered inappropriateinputs for requirements. No decisions can be made out of them.
6.1. Future enhancements
The work presented in our research can be extended in manyinteresting ways. We consider two directions of enhancements.With the objective of improving the efﬁciency of the require-ments analysis activity, the work may be enhanced to offer ananalysis of the model. This could mean the incorporation of seman-tic information and/or existing knowledge into the model, to addimplicit knowledge, and the ability to judge the completeness of theconceptual model and prompt the analyst in the direction of bet-ter formed conceptual models. This activity involves an assessmentof what constitutes ‘sound’ conceptual classes, and what informa-tion is necessary for ‘completeness’. Another way to improve therequirements process could be the ability to quantify the contribu-tion of each relationship or class to the overall speciﬁcation of theconceptual model, i.e., to determine what relationships or opera-tions carry more signiﬁcance to the speciﬁcation of the concept.This can help the participants in the requirements phase, to beaware of the completion percentage of the requirements.
Yet another objective of enhancements could be to improviseon the conceptual model itself, with the objective of reusing themodel during the design phase. This objective also requires seman-tic information of the identiﬁed concepts, to identify and retain onlythe necessary classes, attributes and relations, as suggested by theOO design principles (Larman, 2002).In summary, the next big step to take in either direction wouldbe the incorporation of semantic information in the conceptualmodel, to make sense of the concepts to either improve the con-ceptual model for the requirements analysis, or for conversion to adesign model like a class diagram.AcknowledgementFurther work on this research is getting supported by UGC, NewDelhi, India under Major Research project scheme of EngineeringSciences– F.no. 42-129/2013(SR).
Appendix. Conceptual models generated for EFP andcourse registration
See Figs. 6 and 7.
Image of Fig. 6
Fig. 6. UML style conceptual model for EFP standard case study (Kurt, 1995).
Image of Fig. 7
Fig. 7. UML style conceptual model for Course Registration standard case study (IBM Corp, 2004).
ReferencesAmbler, S., 2005. The elements of UML 2. 0 style. Cambridge University Press.Ambriola, V., Gervasi, V., 2006. On the systematic analysis of natural languagerequirements with CIRCE. Journal of Automated Software Engineering 13(January (1)), 107–167.Bird, S., Klein, E., Loper, E., 2009. Natural Language Processing with Python. O’ReillyMedia.Booch, G., Maksimchuk, R., Michael, E., Young, J., Conallen, J., Houston, A., 2010.Object – Oriented Analysis and Design with Applications. Pearson Education.Burg, J., 1997. Linguistic Instruments in Requirements Engineering. IOS Press.Col, J., 2013. Adjective and a list of Adjectives. In: Enchanted Learning, Available at:http://www.enchantedlearning.com/grammar/partsofspeech/adjectives/News and Events, 2013. European Commission – CORDIS, Available at:http://cordis.europa.eu/fetch?CALLER=EN NEWS EVENT&ACTION=D&DOC=39&CAT=NEWS&QUERY=0132d8bc3aca:de9c:21c94748&RCN=33343Elbendak, M., Vickers, P., Rossiter, N., 2011. Parsed use case descriptions as a basisfor object-oriented class model generation. Journal of Systems and Software 84(July (7)), 1209–1223.Ellson, J., Gansner, E., Koutsoﬁos, L., North, S., Woodhull, G., 2002. Graphviz—Open Source Graph Drawing Tools. Graph Drawing: Lecture Notes in ComputerScience, vol. 2265. Springer, Berlin/Heidelberg, pp. 594–597.IBM Corp: IBM Rational Software, 2004. Section 1: Course Registration Require-ments.Jurafsky, D., Martin, H., 2000. Speech and Language Processing, 1st ed. Pearson Edu-cation.Kurt, W.D., 1995. Applying OMT: A Practical Step-by-Step Guide to Using the ObjectModeling Technique. SIGS Publications, NY, USA.Larman, C., 2002. Applying UML and Patterns – An introduction to Object-OrientedAnalysis and Design and Iterative Development, 3rd ed. Pearson Education India.Lefﬁngwell, D., 2011. Agile Software Requirements: Lean Requirements Prac-tices for Teams, Programs, and the Enterprise, 1st ed. Addison-WesleyProfessional.LindLand, O., Sindre, G., Solvberg, A., 1994. Understanding quality in conceptualmodeling. IEEE Software 11 (March (2)), 42–49.
Loberger, G., Shoup, K., 2009. Webster’s New World English Grammar Handbook.2013. Morphy (7WN) manual page. In: WordNet: A lexical database for English,wordnet@princeton.edu, Available at: http://wordnet.princeton.edu/man/morphy.7WN.htmlMu, Y., Wang, Y., Guo, J., 2009. Extracting software functional requirements from freetext documents. In: International Conference on Information and MultimediaTechnology, Jeju Island, South Korea.2013. Stanford Parser – Spatial Language, Available at: http://projects.csail.mit.edu/spatial/Stanford ParserRumbaugh, J., Blaha, M., Premerlani, W., Eddy, F., Lorensen, W., 1991. Object-Oriented Modeling and Design. Pearson Education.Sanjay, A., Sankar Basu, S., Choudhury, S., 2010. A requirement framework forenablement of automatic generation of domain model. In: Computer Informa-tion Systems and Industrial Management Applications (CISIM), Krackow, vol.10.1109/CISIM. 2010.5643633, pp. 359–364.Vidhu Bhala, R.V., Mala, T., Abirami, S., 2012. Effective visualization of conceptualclass diagrams. In: 2012 International Conference on Recent Advances in Com-puting and Software Systems, Chennai, India, pp. 1–6.Yue, T., Briand, L., Labiche, Y., 2011. A systematic review of transformationapproaches between user requirements and analysis models, 16. Springer:Requirements Engineering, pp. 75–99.Vidhu Bhala R. Vidya Sagar works with Mindtree, India. She pursued her Mastersdegree in the department of Information Science and Technology at Anna University,CEG. She has more than 13 years of experience in the software industry and herinterests are in the area of requirements elicitation and analysis and the ability tovalidate and enhance software requirements elicited from customers. Her currentresearch work includes processing of natural language text to extract artifacts usefulfor requirements analysis and validation.Dr S. Abirami is an Assistant professor in the department of Information Science andTechnology at Anna University, CEG for past 6 years. Her areas of interest includenatural language processing, image processing, multimedia technologies and datamining.
